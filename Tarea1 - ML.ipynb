{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Descomposición sesgo-varianza.\n",
    "\n",
    "a) Considere el conjunto de observaciones $ D = \\{(x_i,y_i)\\}_{i=1}^N $, relacionadas mediante el modelo lineal\n",
    "    \n",
    "$$ y_i = \\theta^T x_i + \\varepsilon_i $$\n",
    "\n",
    "donde $\\{\\varepsilon_i\\}_{i=1}^N$ son observaciones i.i.d. con $\\mathbb{E}[\\varepsilon] = 0$ y $var(\\varepsilon) = \\sigma^2$, $\\theta$ es un parámetro fijo y desconocido. Para un nuevo par, denotado $(x,y)$, no contenido en el conjunto de observaciones $D$, considere la predicción de $y$ mediante $\\hat{y} = \\hat{\\theta}^Tx$, donde $\\hat{\\theta}$ es un estimador del parámetro $\\theta$ basado en $D$. Muestre que el costo cuadrático esperado de predeccir $y$ con $\\hat{y}$ (recuerde que las esperanzas se toman con respecto a la ley de $\\varepsilon$) admite la siguiente descomposición sesgo-varianza:\n",
    "    \n",
    "$$ \\mathbb{E}\\left[ (\\hat{y} -y)^2 \\right]\\, =\\, var(\\hat{y}) + sesgo(\\hat{y})^2 + \\sigma^2, $$\n",
    "\n",
    "donde: i) el primer término es la varianza de la variable aleatoria $\\hat{y}$, con $var(\\hat{y}) = \\mathbb{E}[(\\hat{y} - \\mathbb{E}[\\hat{y}])^2]$ (recuerde que $\\hat{\\theta}$ es una variable aleatoria, pues depende de $D$), ii) el segundo término es el sesgo al cuadrado de la variable aleatoria $\\hat{y}$, con $sesgo(\\hat{y}) = \\mathbb{E}[\\hat{y}-y] = \\mathbb{E}[\\hat{y}] - \\theta^Tx$, y iii) $\\sigma^2$ es la varianza de $\\varepsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demostración:\n",
    "\n",
    "Primero notemos que: el estadístico $\\hat{\\theta}$ es una función del conjunto $D$ de datos, es decir $\\hat{\\theta}(D)$, por lo tanto la estimación $\\hat{y}$ es una función de $D$ y el nuevo valor $x$, es decir $\\hat{y} = \\hat{y}\\,(D,x) = \\hat{\\theta}^Tx$. Dado que $(x,y)\\notin D$, $y$ es independiente a todos los valores $y_i$ en $\\{(x_i,y_i)\\}_{i=1}^N$ (pues las únicas variables aleatorias involucradas son los $\\{\\varepsilon_i\\}_i$, y estas son i.i.d.), por lo tanto $y$ también es independiente a toda función que dependa sólo de este conjunto $D$, es decir $y$ e $\\hat{y}$ son v.a. independientes.\n",
    "\n",
    "Como $y$ e $\\hat{y}$ son independientes, entonces $\\mathbb{E}(y\\hat{y}) = \\mathbb{E}(y)\\,\\mathbb{E}(\\hat{y})$.\n",
    "\n",
    "Además, notemos que $\\mathbb{E}(y) = \\mathbb{E}(\\theta^Tx + \\varepsilon) = \\theta^Tx$, por lo tanto podemos decir que $y = \\mathbb{E}[y] + \\varepsilon$.\n",
    "\n",
    "Con esto tenemos que:\n",
    "\n",
    "$\\mathbb{E}[(\\hat{y} - y)^2] = $\n",
    "\n",
    "$$ \\mathbb{E}\\left[ \\hat{y}^2\\, -\\, 2\\,\\hat{y}\\,y\\,+\\,y^2\\right]\\,=\\,\\mathbb{E}[\\hat{y}^2]\\,-\\,2\\,\\mathbb{E}[\\hat{y}\\,y]\\,+\\,\\mathbb{E}[y^2]$$\n",
    "\n",
    "$$=\\,\\mathbb{E}[\\hat{y}^2]\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}[y^2]\\,=\\,\\mathbb{E}[\\hat{y}^2]\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}\\left[\\left(\\mathbb{E}(y)\\,+\\,\\varepsilon\\right)^2\\right]$$\n",
    "\n",
    "Donde las dos últimas igualdades se ha ocupado lo explicado anteriormente.\n",
    "\n",
    "$$=\\,\\mathbb{E}[\\hat{y}^2]\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}\\left[\\mathbb{E}(y)^2\\,+\\,2\\,\\mathbb{E}(y)\\,\\varepsilon\\,+\\,\\varepsilon^2\\right]$$\n",
    "\n",
    "$$=\\,\\mathbb{E}[\\hat{y}^2]\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}[y]^2\\,+\\,2\\,\\mathbb{E}[y]\\,\\mathbb{E}[\\varepsilon]\\,+\\,\\mathbb{E}[\\varepsilon^2]$$\n",
    "\n",
    "Se ha ocupado que la esperanza es un valor constante, por lo tanto sale de otra esperanza iterada. Además notemos que como $\\mathbb{E}[\\varepsilon] = 0$, entonces $\\mathbb{E}[\\varepsilon^2] = var[\\varepsilon] = \\sigma^2$. Con esto:\n",
    "\n",
    "$$=\\,\\mathbb{E}[\\hat{y}^2]\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}[y]^2\\,+\\,\\sigma^2$$\n",
    "\n",
    "Sólo basta restar y sumar el término $\\mathbb{E}[\\hat{y}]^2$ para llegar a nuestro resultado.\n",
    "\n",
    "$$=\\,\\mathbb{E}[\\hat{y}^2]\\,+\\,\\left(-\\,\\mathbb{E}[\\hat{y}]^2\\,+\\,\\mathbb{E}[\\hat{y}]^2\\right)\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}[y]^2\\,+\\,\\sigma^2$$\n",
    "\n",
    "$$=\\,\\left(\\mathbb{E}[\\hat{y}^2]\\,+\\,-\\,\\mathbb{E}[\\hat{y}]^2\\right)\\,+\\,\\left(\\mathbb{E}[\\hat{y}]^2\\,-\\,2\\,\\mathbb{E}[\\hat{y}]\\,\\mathbb{E}[y]\\,+\\,\\mathbb{E}[y]^2\\right)\\,+\\,\\sigma^2$$\n",
    "\n",
    "$$=\\,var[\\hat{y}]\\,+\\,\\left(\\mathbb{E}[\\hat{y}]\\,-\\,\\mathbb{E}[y]\\right)^2\\,+\\,\\sigma^2$$\n",
    "\n",
    "$$=\\,var[\\hat{y}]\\,+\\,\\left(\\mathbb{E}[\\hat{y}\\,-\\,y]\\right)^2\\,+\\,\\sigma^2$$\n",
    "\n",
    "$$=\\,var[\\hat{y}]\\,+\\,\\left(sesgo(\\hat{y})\\right)^2\\,+\\,\\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para los parámetros de mínimos cuadrados $\\theta_{MC} = \\left(X^TX\\right)^{-1}X^TY$ y de mínimos cuadrados regularizados $\\theta_{MCR} = \\left(X^TX + \\rho I\\right)^{-1}X^TY$ calcule el sesgo y la varianza de la predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero notemos que para matrices de datos, el modelo se escribe como:\n",
    "\n",
    "$$ Y\\, =\\, X\\cdot\\theta\\,+\\,\\mathcal{E}$$\n",
    "\n",
    "donde $\\cdot$ es el producto matricial y $\\mathcal{E}$ es el vector de errores aleatorios, y:\n",
    "\n",
    "$$\\mathbb{E}(Y) = X\\cdot\\theta$$\n",
    "\n",
    "#### Para mínimos cuadrados:\n",
    "\n",
    "$sesgo(\\hat{Y}_{MC}) = $\n",
    "\n",
    "$$ \\mathbb{E}[\\hat{Y}_{MC}] - X\\cdot\\theta = \\mathbb{E}\\left[X\\cdot\\theta_{MC}\\right] - X\\cdot\\theta $$\n",
    "\n",
    "$$ =\\,X\\cdot\\mathbb{E}\\left[\\theta_{MC}\\right]\\,-\\,X\\cdot\\theta $$\n",
    "\n",
    "$$ =\\,X\\cdot\\mathbb{E}\\left[\\left(X^TX\\right)^{-1}X^T\\,Y\\right]\\,-\\,X\\cdot\\theta $$\n",
    "\n",
    "$$ =\\,X\\left(X^TX\\right)^{-1}X^T\\cdot\\mathbb{E}\\left[\\,Y\\right]\\,-\\,X\\cdot\\theta $$\n",
    "\n",
    "$$ =\\,X\\left[\\left(X^TX\\right)^{-1}X^TX\\right]\\cdot\\theta\\,-\\,X\\cdot\\theta $$\n",
    "\n",
    "$$ = \\,X\\cdot\\theta\\,-\\,X\\cdot\\theta\\,=\\,0$$\n",
    "\n",
    "\n",
    "Como ya notamos, la predicción $\\hat{Y}_{MC}$ es insesgada con respecto al valor esperado de $Y$, por lo tanto $\\mathbb{E}(\\hat{Y}_{MC}) = X\\cdot\\theta$.\n",
    "\n",
    "$var(\\hat{Y}_{MC}) =$\n",
    "\n",
    "$$ \\mathbb{E}\\left[\\left(\\hat{Y}_{MC}\\right)^T\\hat{Y}_{MC}\\right]\\,-\\,\\mathbb{E}\\left[\\hat{Y}_{MC}\\right]^T\\mathbb{E}\\left[\\hat{Y}_{MC}\\right]$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Regresión Lineal\n",
    "\n",
    "Como base de datos del experimento se utilizará el archivo **Housing.csv**, este corresponde a un data set que posee precios de casas de algunas localidades de USA. Este data set consta de una variable $X$, que corresponde al ingreso promedio de la población de esa área (*Avg Area Income*), e $Y$, que corresponde al precio de las casas. El objetivo de esta pregunta es aprender una función lineal que relaciones $X$ e $Y$, así un agente inmobiliario que no tiene información sobre el precio de las casas en una nueva localidad pueda fijarle un precio a estas en base al ingreso promedio del área.\n",
    "Para una correcta comparación de los estimadores la base de datos viene dividida en dos conjuntos, entrenamiento (*in-sample*) y validación (*out-of-sample*).\n",
    "\n",
    "Para esto deberá:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Cargar los datos desde el archivo **Housing.csv** y graficarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('C:/Users/paula/Desktop/Bruno Cosas/jupyter/T1_Housing.csv')\n",
    "\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = data.columns\n",
    "avg = data[cols[1]]\n",
    "price = data[cols[2]]\n",
    "\n",
    "plt.figure(figsize = (15,7))\n",
    "plt.plot(avg,price, '*')\n",
    "plt.xlabel('Ingreso promedio')\n",
    "plt.ylabel('Precio')\n",
    "plt.title('Precio de las casas en función del ingreso promedio en localidades.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Implemente el estimador de mínimos cuadrados regularizado usando regularización *ridge* y obtenga el vector de parámetros $\\theta$ para diferentes valores de $\\rho\\,\\in\\,[0,10]$ incluyendo los límites. Para esto  implemente la función $\\texttt{reg_lineal(X,Y,rho)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_lineal(X,Y,rho):\n",
    "    #X e Y deben ser vectores array de numpy\n",
    "    #rho debe ser un float\n",
    "    x1 = np.dot(X.T,X)\n",
    "    if np.shape(x1) == ():\n",
    "        x2 = (x1 + rho)**(-1)\n",
    "    else:\n",
    "        n = np.shape(x1)\n",
    "        x2 = np.linalg.inv(x1 + rho*np.eye(n))\n",
    "    \n",
    "    x3 = np.dot(X.T,Y)\n",
    "    theta = np.dot(x2,x3)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar conjunto de entrenamiento (1) y conjunto de validación (0)\n",
    "\n",
    "train = data[data[cols[3]]==1]\n",
    "test = data[data[cols[3]]==0]\n",
    "\n",
    "# Eligiremos 500 valores entre 0 y 10 con el comando linspace\n",
    "rhos = np.linspace(0,10,500)\n",
    "thetas =[]\n",
    "X = train[cols[1]]\n",
    "Y = train[cols[2]]\n",
    "\n",
    "for r in rhos:\n",
    "    thetas.append(reg_lineal(X,Y,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Grafique el valor de los parámetros estimados para los valores de $\\rho$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,7))\n",
    "plt.plot(rhos,thetas)\n",
    "plt.xlabel('Parámetro de regularización.')\n",
    "plt.ylabel('Parámetro estimado del modelo.')\n",
    "plt.title('Parámetro en función de la regularización.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Grafique el error cuadrático medio y la varianza  de la predicción  para los valores  de $\\rho$ tanto en el conjunto de entrenamiento  como en el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para conjunto de entrenamiento:\n",
    "# varianza:\n",
    "varianza_train = []\n",
    "for t in thetas:\n",
    "    y_est = t*X\n",
    "    varianza_train.append(np.var(y_est))\n",
    "\n",
    "#ECM:\n",
    "ECM_train = []\n",
    "for t in thetas:\n",
    "    error = t*X - Y\n",
    "    ec = [a**2 for a in error]\n",
    "    ECM_train.append(np.mean(ec))\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.subplot(121)\n",
    "plt.xlabel('Parámetro de Regularización')\n",
    "plt.title('Varianza entrenamiento.')\n",
    "plt.plot(rhos,varianza_train, '*', color = 'r', label = 'Varianza.')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.xlabel('Parámetro de Regularización')\n",
    "plt.title('Error Cuadrático Medio entrenamiento.')\n",
    "plt.plot(rhos,ECM_train, '*', color = 'b', label = 'E.C.M.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para conjunto de validación:\n",
    "X_test = test[cols[1]]\n",
    "Y_test = test[cols[2]]\n",
    "\n",
    "# varianza:\n",
    "varianza_test = []\n",
    "for t in thetas:\n",
    "    y_est = t*X_test\n",
    "    varianza_test.append(np.var(y_est))\n",
    "\n",
    "#ECM:\n",
    "ECM_test = []\n",
    "for t in thetas:\n",
    "    error = t*X_test - Y_test\n",
    "    ec = [a**2 for a in error]\n",
    "    ECM_test.append(np.mean(ec))\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "plt.subplot(121)\n",
    "plt.xlabel('Parámetro de Regularización')\n",
    "plt.title('Varianza validación.')\n",
    "plt.plot(rhos,varianza_test, '*', color = 'r', label = 'Varianza.')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.xlabel('Parámetro de Regularización')\n",
    "plt.title('Error Cuadrático Medio validación.')\n",
    "plt.plot(rhos,ECM_test, '*', color = 'b', label = 'E.C.M.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Grafique la ecuación de la recta  con los parámetros estimados  para diferentes valores de $\\rho$ junto a los datos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crearemos un nuevo conjunto de valores de rho que sea más pequeño y graficable\n",
    "\n",
    "rho2 = np.linspace(0,100,7)\n",
    "thetas2 = []\n",
    "for r in rho2:\n",
    "    thetas2.append(reg_lineal(X,Y,r))\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.plot(avg,price, '*', color = 'b')\n",
    "for i in range(len(thetas2)):\n",
    "    y = thetas2[i]*avg\n",
    "    plt.plot(avg,y, label = 'rho = '+str(rho2[i]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
